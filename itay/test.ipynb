{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Initialize"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7035aef53d01e8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "277cbb0fbc7f8795"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No CUDA runtime is found, using CUDA_HOME='C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.8'\n",
      "C:\\Users\\owner\\anaconda3\\envs\\open-mmlab\\lib\\site-packages\\mmcv\\__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from mmhuman3d.data.data_structures.human_data import HumanData\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-08T13:04:01.562279100Z",
     "start_time": "2024-04-08T13:03:54.668658300Z"
    }
   },
   "id": "initial_id",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Path"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "278d0c58f31a42a9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_root = Path('D:/MMLAB/mmhuman3d/data/Samples/run_0/')\n",
    "input_vid = data_root/ 'yoga.mp4'\n",
    "mesh_vid = data_root/ 'smplx.mp4'\n",
    "output_vid = data_root/ 'output.mp4'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T13:04:01.585622900Z",
     "start_time": "2024-04-08T13:04:01.563279200Z"
    }
   },
   "id": "cacf9c38e56a6d98",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Constants"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1adcc223d77196ad"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                  CoM      Mass Radius of gyration        proximal  \\\nPelvis            0.5  0.148071               0.31       right hip   \nThorax_a         0.63  0.185089               0.31        left hip   \nThorax_b         0.63  0.185089               0.31       right hip   \nHead              0.5  0.084463              1.116            neck   \nRight Femur     0.567  0.104275               0.54       right hip   \nLeft Femur      0.567  0.104275               0.54        left hip   \nRight Tibia     0.567  0.048488              0.528      right knee   \nLeft Tibia      0.567  0.048488              0.528       left knee   \nRight Humorous  0.564  0.029197              0.542  right shoulder   \nLeft Humorous   0.564  0.029197              0.542   left shoulder   \nRight Radius     0.57  0.016684              0.526     right elbow   \nLeft Radius      0.57  0.016684              0.526      left elbow   \n\n                     distal  proximal_idx  distal_idx  \nPelvis             left hip             2           3  \nThorax_a               neck             3          12  \nThorax_b               neck             2          12  \nHead               head top            12          13  \nRight Femur      right knee             2           1  \nLeft Femur        left knee             3           4  \nRight Tibia     right ankle             1           0  \nLeft Tibia       left ankle             4           5  \nRight Humorous  right elbow             8           7  \nLeft Humorous    left elbow             9          10  \nRight Radius    right wrist             7           6  \nLeft Radius      left wrist            10          11  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CoM</th>\n      <th>Mass</th>\n      <th>Radius of gyration</th>\n      <th>proximal</th>\n      <th>distal</th>\n      <th>proximal_idx</th>\n      <th>distal_idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Pelvis</th>\n      <td>0.5</td>\n      <td>0.148071</td>\n      <td>0.31</td>\n      <td>right hip</td>\n      <td>left hip</td>\n      <td>2</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>Thorax_a</th>\n      <td>0.63</td>\n      <td>0.185089</td>\n      <td>0.31</td>\n      <td>left hip</td>\n      <td>neck</td>\n      <td>3</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>Thorax_b</th>\n      <td>0.63</td>\n      <td>0.185089</td>\n      <td>0.31</td>\n      <td>right hip</td>\n      <td>neck</td>\n      <td>2</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>Head</th>\n      <td>0.5</td>\n      <td>0.084463</td>\n      <td>1.116</td>\n      <td>neck</td>\n      <td>head top</td>\n      <td>12</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>Right Femur</th>\n      <td>0.567</td>\n      <td>0.104275</td>\n      <td>0.54</td>\n      <td>right hip</td>\n      <td>right knee</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Left Femur</th>\n      <td>0.567</td>\n      <td>0.104275</td>\n      <td>0.54</td>\n      <td>left hip</td>\n      <td>left knee</td>\n      <td>3</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>Right Tibia</th>\n      <td>0.567</td>\n      <td>0.048488</td>\n      <td>0.528</td>\n      <td>right knee</td>\n      <td>right ankle</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Left Tibia</th>\n      <td>0.567</td>\n      <td>0.048488</td>\n      <td>0.528</td>\n      <td>left knee</td>\n      <td>left ankle</td>\n      <td>4</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>Right Humorous</th>\n      <td>0.564</td>\n      <td>0.029197</td>\n      <td>0.542</td>\n      <td>right shoulder</td>\n      <td>right elbow</td>\n      <td>8</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>Left Humorous</th>\n      <td>0.564</td>\n      <td>0.029197</td>\n      <td>0.542</td>\n      <td>left shoulder</td>\n      <td>left elbow</td>\n      <td>9</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>Right Radius</th>\n      <td>0.57</td>\n      <td>0.016684</td>\n      <td>0.526</td>\n      <td>right elbow</td>\n      <td>right wrist</td>\n      <td>7</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>Left Radius</th>\n      <td>0.57</td>\n      <td>0.016684</td>\n      <td>0.526</td>\n      <td>left elbow</td>\n      <td>left wrist</td>\n      <td>10</td>\n      <td>11</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoints_dict ={0:\"right ankle\",1:\"right knee\", 2:\"right hip\", 3:\"left hip\", 4:\"left knee\", 5:\"left ankle\", 6:\"right wrist\", 7:\"right elbow\", 8:\"right shoulder\", 9:\"left shoulder\", 10:\"left elbow\", 11:\"left wrist\", 12:\"neck\", 13:\"head top\"}\n",
    "\n",
    "data = {\n",
    "    \"Pelvis\": {\"CoM\": 0.5, \"Mass\": 0.142, \"Radius of gyration\": 0.31, \"proximal\": \"right hip\" , \"distal\": \"left hip\"},\n",
    "    \"Thorax_a\": {\"CoM\": 0.63, \"Mass\": 0.355/2, \"Radius of gyration\": 0.31, \"proximal\": \"left hip\" , \"distal\": \"neck\"},\n",
    "    \"Thorax_b\": {\"CoM\": 0.63, \"Mass\": 0.355/2, \"Radius of gyration\": 0.31, \"proximal\": \"right hip\" , \"distal\": \"neck\"},\n",
    "    \"Head\": {\"CoM\": 0.5, \"Mass\": 0.081, \"Radius of gyration\": 1.116, \"proximal\": \"neck\" , \"distal\": \"head top\"},\n",
    "    \"Right Femur\": {\"CoM\": 0.567, \"Mass\": 0.1, \"Radius of gyration\": 0.54, \"proximal\": \"right hip\" , \"distal\": \"right knee\"},\n",
    "    \"Left Femur\": {\"CoM\": 0.567, \"Mass\": 0.1, \"Radius of gyration\": 0.54, \"proximal\": \"left hip\" , \"distal\": \"left knee\"},\n",
    "    \"Right Tibia\": {\"CoM\": 0.567, \"Mass\": 0.0465, \"Radius of gyration\": 0.528, \"proximal\": \"right knee\" , \"distal\": \"right ankle\"},\n",
    "    \"Left Tibia\": {\"CoM\": 0.567, \"Mass\": 0.0465, \"Radius of gyration\": 0.528, \"proximal\": \"left knee\" , \"distal\": \"left ankle\"},\n",
    "    \"Right Humorous\": {\"CoM\": 0.564, \"Mass\": 0.028, \"Radius of gyration\": 0.542, \"proximal\": \"right shoulder\" , \"distal\": \"right elbow\"},\n",
    "    \"Left Humorous\": {\"CoM\": 0.564, \"Mass\": 0.028, \"Radius of gyration\": 0.542, \"proximal\": \"left shoulder\" , \"distal\": \"left elbow\"},\n",
    "    \"Right Radius\": {\"CoM\": 0.57, \"Mass\": 0.016, \"Radius of gyration\": 0.526, \"proximal\": \"right elbow\" , \"distal\": \"right wrist\"},\n",
    "    \"Left Radius\": {\"CoM\": 0.57, \"Mass\": 0.016, \"Radius of gyration\": 0.526, \"proximal\": \"left elbow\" , \"distal\": \"left wrist\"},\n",
    "    #\"Foot\": {\"CoM\": 0.5, \"Mass\": 0.0145, \"Radius of gyration\": 0.69, \"proximal\": \"L5/S1\" , \"distal\": \"Hip\"},\n",
    "    #\"Hand\": {\"CoM\": 0.6205, \"Mass\": 0.006, \"Radius of gyration\": 0.44, \"proximal\": \"L5/S1\" , \"distal\": \"Hip\"},\n",
    "}\n",
    "# \n",
    "segments_mat = pd.DataFrame(data).T\n",
    "# redistribute the Mass so the sum will be 1 \n",
    "segments_mat['Mass'] = segments_mat['Mass'] / segments_mat['Mass'].sum()\n",
    "# add to each segment the index of the proximal and distal segment from the keypoints_dict\n",
    "segments_mat['proximal_idx'] = segments_mat['proximal'].apply(lambda x: list(keypoints_dict.keys())[list(keypoints_dict.values()).index(x)])\n",
    "segments_mat['distal_idx'] = segments_mat['distal'].apply(lambda x: list(keypoints_dict.keys())[list(keypoints_dict.values()).index(x)])\n",
    "\n",
    "segments_mat"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T13:04:02.078562100Z",
     "start_time": "2024-04-08T13:04:02.003562500Z"
    }
   },
   "id": "9c8b322409ff1553",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load HumanData   "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3125e9838af1d709"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "h_data = HumanData.fromfile(data_root /'inference_result.npz')\n",
    "keypoints = h_data['keypoints3d'][:, :, :3]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T13:04:03.791185600Z",
     "start_time": "2024-04-08T13:04:03.668825600Z"
    }
   },
   "id": "d623be3b5e41cd54",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualization functions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9383aa3ad1fdd69b"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def visualize_3d_keypoints(keypoints,M = None,bound = True):\n",
    "    # Extracting dimensions\n",
    "    k, _ = keypoints.shape\n",
    "    # Initialize figure and 3D axis\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    if bound:\n",
    "        # Setting axis limits (You might need to adjust these based on your data)\n",
    "        ax.set_xlim([-1,1])\n",
    "        ax.set_ylim([-1,1])\n",
    "        ax.set_zlim([-1,1])\n",
    "    else:\n",
    "        ax.set_xlim([keypoints[:,0].min(),keypoints[:,0].max()])\n",
    "        ax.set_ylim([keypoints[:,1].min(),keypoints[:,1].max()])\n",
    "        ax.set_zlim([keypoints[:,2].min(),keypoints[:,2].max()])\n",
    "    \n",
    "    # rotate the 3d plot x zero, y zero is at the bottom left\n",
    "    #\n",
    "    # set origin top left corner\n",
    "    ax.invert_yaxis()\n",
    "    current_view = ax.view_init()\n",
    "    ax.view_init(elev=80, azim=-90,roll=0)\n",
    "    \n",
    "    # Plot keypoints\n",
    "    for i in range(k):\n",
    "        ax.scatter(keypoints[i,0], keypoints[i,1], keypoints[i,2])\n",
    "        # add number to each keypoint\n",
    "        #ax.text(keypoints[i,0], keypoints[i,1], keypoints[i,2], '%s' % (str(keypoints_dict[i])), size=10, zorder=1, color='k')\n",
    "    if M is not None:\n",
    "        ax.scatter(M[0], M[1], M[2], c='r', marker='o')\n",
    "        ax.text(M[0], M[1], M[2], 'CoM', size=10, zorder=1, color='k')\n",
    "        \n",
    "    return fig\n",
    "\n",
    "# Example usage\n",
    "# Assuming you have defined keypoints_array and M\n",
    "visualize_3d_keypoints(keypoints[0,:,:],bound = False);"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T13:04:05.108472200Z",
     "start_time": "2024-04-08T13:04:04.624440400Z"
    }
   },
   "id": "d3641b48d953b070",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Calculate Center of Mass"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "794bb6869c838b8c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(97, 3)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = segments_mat.CoM.values\n",
    "w = segments_mat.Mass.values\n",
    "\n",
    "proximal,distal = keypoints[:,segments_mat.proximal_idx.values,:], keypoints[:,segments_mat.distal_idx.values,:]\n",
    "p_com = (proximal * l[:,None] + distal * (1-l)[:,None])\n",
    "# M is the matrix that average over the keypoints using the weights (w)\n",
    "M = np.sum(p_com * w[None,:,None], axis = 1)\n",
    "M.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T13:04:12.630996200Z",
     "start_time": "2024-04-08T13:04:12.569474700Z"
    }
   },
   "id": "553158a20a52b40a",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import webbrowser\n",
    "\n",
    "\n",
    "\n",
    "def scatter_3d(data_list, output_html =\"\", names = None, colors =None, size = 5):\n",
    "    if isinstance(size, int):\n",
    "        size = [size]*len(data_list)\n",
    "    if not isinstance(size, list) :\n",
    "        raise ValueError(\"size should be an integer or a list of integers\") \n",
    "    if colors is None:\n",
    "        colors = [\"blue\",\"red\",\"green\",\"yellow\",\"black\",\"purple\",\"orange\",\"pink\",\"brown\",\"cyan\",\"magenta\",\"grey\",\"lightblue\"]\n",
    "    if names is None:\n",
    "        names = [f\"Data {i}\" for i in range(len(data_list))]\n",
    "    \n",
    "\n",
    "    # Create figure\n",
    "    fig = go.Figure()\n",
    "    for j, data in enumerate(data_list):\n",
    "        fig.add_trace(go.Scatter3d(x=data[0, :, 0], y=data[0, :, 1], z=data[0, :, 2],\n",
    "                                   mode=\"markers\", marker=dict(size=size[j], color=colors[j]),\n",
    "                                   name=names[j]),\n",
    "                      )\n",
    "    # Combine frames alternately\n",
    "    max_length = max([len(data) for data in data_list])\n",
    "    \n",
    "    # Define frames where both data and M are updated\n",
    "    all_frames = []\n",
    "    for i in range(max_length):\n",
    "        frame_data = []\n",
    "        for j, data in enumerate(data_list):\n",
    "            if i < len(data):\n",
    "                frame_data.append(go.Scatter3d(x=data[i, :, 0], y=data[i, :, 1], z=data[i, :, 2],\n",
    "                                               mode=\"markers\", marker=dict(size=size[j], color=colors[j]),)\n",
    "                                  )\n",
    "    \n",
    "        all_frames.append(go.Frame(data=frame_data, name=f'frame{i}'))\n",
    "    \n",
    "    # Update frames\n",
    "    fig.update(frames=all_frames)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def frame_args(duration):\n",
    "        return {\n",
    "            \"frame\": {\"duration\": duration},\n",
    "            \"mode\": \"immediate\",\n",
    "            \"fromcurrent\": True,\n",
    "            \"transition\": {\"duration\": duration, \"easing\": \"linear\"},\n",
    "        }\n",
    "    \n",
    "    \n",
    "    sliders = [\n",
    "        {\"pad\": {\"b\": 10, \"t\": 60},\n",
    "         \"len\": 0.9,\n",
    "         \"x\": 0.1,\n",
    "         \"y\": 0,\n",
    "    \n",
    "         \"steps\": [\n",
    "             {\"args\": [[f.name], frame_args(0)],\n",
    "              \"label\": str(k),\n",
    "              \"method\": \"animate\",\n",
    "              } for k, f in enumerate(fig.frames)\n",
    "         ]\n",
    "         }\n",
    "    ]\n",
    "    \n",
    "    fig.update_layout(\n",
    "        updatemenus=[{\"buttons\": [\n",
    "            {\n",
    "                \"args\": [None, frame_args(50)],\n",
    "                \"label\": \"Play\",\n",
    "                \"method\": \"animate\",\n",
    "            },\n",
    "            {\n",
    "                \"args\": [[None], frame_args(0)],\n",
    "                \"label\": \"Pause\",\n",
    "                \"method\": \"animate\",\n",
    "            }],\n",
    "            \"direction\": \"left\",\n",
    "            \"pad\": {\"r\": 10, \"t\": 70},\n",
    "            \"type\": \"buttons\",\n",
    "            \"x\": 0.1,\n",
    "            \"y\": 0,\n",
    "        }\n",
    "        ],\n",
    "        sliders=sliders,\n",
    "        scene=dict(xaxis=dict(range=[-1.2, 1.2], autorange=False),\n",
    "                   yaxis=dict(range=[-1.2, 1.2], autorange=False),\n",
    "                   zaxis=dict(range=[-1.2, 1.2], autorange=False),\n",
    "                   aspectmode=\"cube\"\n",
    "    \n",
    "                   )\n",
    "    )\n",
    "    # invert the y axis (ax.invert_yaxis())\n",
    "    \n",
    "    # setup the initial view of the 3d plot so the top left corner is -1,-1\n",
    "    fig.update_layout(scene=dict(camera=dict(up=dict(x=0, y=0, z=0),\n",
    "                                             center=dict(x=0, y=0, z=0),\n",
    "                                             eye=dict(x=1, y=-1, z=-2)\n",
    "                                             )\n",
    "                                   )\n",
    "                      )\n",
    "    # change to white theme\n",
    "    fig.update_layout(template=\"plotly_white\")\n",
    "    \n",
    "    # Save the figure as an HTML file\n",
    "    if output_html:\n",
    "        if not output_html.endswith(\".html\"):\n",
    "            output_html += \".html\"\n",
    "        fig.write_html(output_html)\n",
    "        webbrowser.open(output_html)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "f = scatter_3d(data_list =[keypoints,np.expand_dims(M.copy(), 1)],\n",
    "           output_html = str(data_root/'3d_keypoints.html'),\n",
    "           names = [\"Keypoints\", \"CoM\"],\n",
    "           colors = [\"blue\", \"red\"],\n",
    "           size = 5)       "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T13:04:18.671530100Z",
     "start_time": "2024-04-08T13:04:16.401157900Z"
    }
   },
   "id": "c9a6822504d0a14d",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "# use paper volume to calculate the CoM"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "593cb249c8c1f8b7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from itay.utils.part_volumes import PartVolume \n",
    "import torch.nn as nn\n",
    "import pickle as pkl\n",
    "import os.path as osp\n",
    "ESSENTIALS_DIR = 'D:/MMLAB/mmhuman3d/itay/data/essentials'\n",
    "SMPL_PART_BOUNDS = f'{ESSENTIALS_DIR}/yogi_segments/smpl/part_meshes_ply/smpl_segments_bounds.pkl'\n",
    "FID_TO_PART = f'{ESSENTIALS_DIR}/yogi_segments/smpl/part_meshes_ply/fid_to_part.pkl'\n",
    "PART_VID_FID = f'{ESSENTIALS_DIR}/yogi_segments/smpl/part_meshes_ply/smpl_part_vid_fid.pkl'\n",
    "HD_SMPL_MAP  = f'{ESSENTIALS_DIR}/hd_model/smpl/smpl_neutral_hd_sample_from_mesh_out.pkl'\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T12:42:58.174297600Z",
     "start_time": "2024-04-08T12:42:58.117836600Z"
    }
   },
   "id": "ba143cdf5371a7fc",
   "execution_count": 181
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def sparse_batch_mm(m1, m2):\n",
    "    \"\"\"\n",
    "    https://github.com/pytorch/pytorch/issues/14489\n",
    "\n",
    "    m1: sparse matrix of size N x M\n",
    "    m2: dense matrix of size B x M x K\n",
    "    returns m1@m2 matrix of size B x N x K\n",
    "    \"\"\"\n",
    "\n",
    "    batch_size = m2.shape[0]\n",
    "    # stack m2 into columns: (B x N x K) -> (N, B, K) -> (N, B * K)\n",
    "    m2_stack = m2.transpose(0, 1).reshape(m1.shape[1], -1)\n",
    "    result = m1.mm(m2_stack).reshape(m1.shape[0], batch_size, -1) \\\n",
    "               .transpose(1, 0)\n",
    "    return result\n",
    "\n",
    "class HDfier():\n",
    "    def __init__(self, model_type='smpl', device='cuda'):\n",
    "        hd_operator_path = osp.join(ESSENTIALS_DIR, 'hd_model', model_type,\n",
    "                                    f'{model_type}_neutral_hd_vert_regressor_sparse.npz')\n",
    "        hd_operator = np.load(hd_operator_path)\n",
    "        self.hd_operator = torch.sparse.FloatTensor(\n",
    "            torch.tensor(hd_operator['index_row_col']),\n",
    "            torch.tensor(hd_operator['values']),\n",
    "            torch.Size(hd_operator['size']))\n",
    "        self.model_type = model_type\n",
    "        self.device = device\n",
    "\n",
    "    def hdfy_mesh(self, vertices):\n",
    "        \"\"\"\n",
    "        Applies a regressor that maps SMPL vertices to uniformly distributed vertices\n",
    "        \"\"\"\n",
    "        # device = body.vertices.device\n",
    "        # check if vertices ndim are 3, if not , add a new axis\n",
    "        if vertices.dim() != 3:\n",
    "            # batchify the vertices\n",
    "            vertices = vertices[None, :, :]\n",
    "\n",
    "        # check if vertices are an ndarry, if yes, make pytorch tensor\n",
    "        if isinstance(vertices, np.ndarray):\n",
    "            vertices = torch.from_numpy(vertices).to(self.device)\n",
    "\n",
    "        vertices = vertices.to(torch.double)\n",
    "\n",
    "        if self.hd_operator.device != vertices.device:\n",
    "            self.hd_operator = self.hd_operator.to(vertices.device)\n",
    "        hd_verts = sparse_batch_mm(self.hd_operator, vertices).to(torch.float)\n",
    "        return hd_verts"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T12:42:59.672967300Z",
     "start_time": "2024-04-08T12:42:59.636272800Z"
    }
   },
   "id": "9b7632ee44265003",
   "execution_count": 182
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class StabilityLossCoP(nn.Module):\n",
    "    def __init__(self,\n",
    "                 faces,\n",
    "                 cop_w = 10,\n",
    "                 cop_k = 100,\n",
    "                 contact_thresh=0.1,\n",
    "                 model_type='smpl',\n",
    "                 device='cuda',\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        Loss that ensures that the COM of the SMPL mesh is close to the center of support \n",
    "        \"\"\"\n",
    "        if model_type == 'smpl':\n",
    "            num_faces = 13776\n",
    "            num_verts_hd = 20000\n",
    "\n",
    "        assert faces is not None, 'Faces tensor is none'\n",
    "        if type(faces) is not torch.Tensor:\n",
    "            faces = torch.tensor(faces.astype(np.int64), dtype=torch.long).to(device)\n",
    "        self.register_buffer('faces', faces)\n",
    "\n",
    "        self.cop_w = cop_w\n",
    "        self.cop_k = cop_k\n",
    "        self.contact_thresh = contact_thresh\n",
    "\n",
    "        self.hdfy_op = HDfier(model_type=model_type)\n",
    "\n",
    "        with open(SMPL_PART_BOUNDS, 'rb') as f:\n",
    "            d = pkl.load(f)\n",
    "            self.part_bounds = {k: d[k] for k in sorted(d)}\n",
    "        self.part_order = sorted(self.part_bounds)\n",
    "\n",
    "        with open(PART_VID_FID, 'rb') as f:\n",
    "            self.part_vid_fid = pkl.load(f)\n",
    "\n",
    "        # mapping between vid_hd and fid\n",
    "        with open(HD_SMPL_MAP, 'rb') as f:\n",
    "            faces_vert_is_sampled_from = pkl.load(f)['faces_vert_is_sampled_from']\n",
    "        index_row_col = torch.stack(\n",
    "            [torch.LongTensor(np.arange(0, num_verts_hd)), torch.LongTensor(faces_vert_is_sampled_from)], dim=0)\n",
    "        values = torch.ones(num_verts_hd, dtype=torch.float)\n",
    "        size = torch.Size([num_verts_hd, num_faces])\n",
    "        hd_vert_on_fid = torch.sparse.FloatTensor(index_row_col, values, size)\n",
    "\n",
    "        # mapping between fid and part label\n",
    "        with open(FID_TO_PART, 'rb') as f:\n",
    "            fid_to_part_dict = pkl.load(f)\n",
    "        fid_to_part = torch.zeros([len(fid_to_part_dict.keys()), len(self.part_order)], dtype=torch.float32)\n",
    "        for fid, partname in fid_to_part_dict.items():\n",
    "            part_idx = self.part_order.index(partname)\n",
    "            fid_to_part[fid, part_idx] = 1.\n",
    "\n",
    "        # mapping between vid_hd and part label\n",
    "        self.hd_vid_in_part = self.vertex_id_to_part_mapping(hd_vert_on_fid, fid_to_part)\n",
    "\n",
    "    def compute_triangle_area(self, triangles):\n",
    "        ### Compute the area of each triangle in the mesh\n",
    "        # Compute the cross product of the two vectors of each triangle\n",
    "        # Then compute the length of the cross product\n",
    "        # Finally, divide by 2 to get the area of each triangle\n",
    "\n",
    "        vectors = torch.diff(triangles, dim=2)\n",
    "        crosses = torch.cross(vectors[:, :, 0], vectors[:, :, 1])\n",
    "        area = torch.norm(crosses, dim=2) / 2\n",
    "        return area\n",
    "\n",
    "    def compute_per_part_volume(self, vertices):\n",
    "        \"\"\"\n",
    "        Compute the volume of each part in the reposed mesh\n",
    "        \"\"\"\n",
    "        part_volume = []\n",
    "        for part_name, part_bounds in self.part_bounds.items():\n",
    "            # get part vid and fid\n",
    "            part_vid = torch.LongTensor(self.part_vid_fid[part_name]['vert_id']).to(vertices.device)\n",
    "            part_fid = torch.LongTensor(self.part_vid_fid[part_name]['face_id']).to(vertices.device)\n",
    "            pv = PartVolume(part_name, vertices, self.faces)\n",
    "            for bound_name, bound_vids in part_bounds.items():\n",
    "                pv.close_mesh(bound_vids)\n",
    "            # add extra vids and fids to original part ids\n",
    "            new_vert_ids = torch.LongTensor(pv.new_vert_ids).to(vertices.device)\n",
    "            new_face_ids = torch.LongTensor(pv.new_face_ids).to(vertices.device)\n",
    "            part_vid = torch.cat((part_vid, new_vert_ids), dim=0)\n",
    "            part_fid = torch.cat((part_fid, new_face_ids), dim=0)\n",
    "            pv.extract_part_triangles(part_vid, part_fid)\n",
    "            part_volume.append(pv.part_volume())\n",
    "        return torch.vstack(part_volume).permute(1,0).to(vertices.device)\n",
    "\n",
    "    def vertex_id_to_part_volume_mapping(self, per_part_volume, device):\n",
    "        batch_size = per_part_volume.shape[0]\n",
    "        self.hd_vid_in_part = self.hd_vid_in_part.to(device)\n",
    "        hd_vid_in_part = self.hd_vid_in_part[None, :, :].repeat(batch_size, 1, 1)\n",
    "        vid_to_vol = torch.bmm(hd_vid_in_part, per_part_volume[:, :, None])\n",
    "        return vid_to_vol\n",
    "\n",
    "    def vertex_id_to_part_mapping(self, hd_vert_on_fid, fid_to_part):\n",
    "        vid_to_part = torch.mm(hd_vert_on_fid, fid_to_part)\n",
    "        return vid_to_part\n",
    "\n",
    "    def forward(self, vertices):\n",
    "        # Note: the vertices should be aligned along y-axis and in world coordinates\n",
    "        batch_size = vertices.shape[0]\n",
    "        # calculate per part volume\n",
    "        per_part_volume = self.compute_per_part_volume(vertices)\n",
    "        # sample 20k vertices uniformly on the smpl mesh\n",
    "        vertices_hd = self.hdfy_op.hdfy_mesh(vertices)\n",
    "        # get volume per vertex id in the hd mesh\n",
    "        volume_per_vert_hd = self.vertex_id_to_part_volume_mapping(per_part_volume, vertices.device)\n",
    "        # calculate com using volume weighted mean\n",
    "        com = torch.sum(vertices_hd * volume_per_vert_hd, dim=1) / torch.sum(volume_per_vert_hd, dim=1)\n",
    "\n",
    "        # # get COM of the SMPLX mesh\n",
    "        # triangles = torch.index_select(vertices, 1, self.faces.view(-1)).reshape(batch_size, -1, 3, 3)\n",
    "        # triangle_centroids = torch.mean(triangles, dim=2)\n",
    "        # triangle_area = self.compute_triangle_area(triangles)\n",
    "        # com_naive = torch.einsum('bij,bi->bj', triangle_centroids, triangle_area) / torch.sum(triangle_area, dim=1)\n",
    "\n",
    "        # pressure based center of support\n",
    "        ground_plane_height = 0.0\n",
    "        eps = 1e-6\n",
    "        vertex_height = (vertices_hd[:, :, 1] - ground_plane_height)\n",
    "        inside_mask = (vertex_height < 0.0).float()\n",
    "        outside_mask = (vertex_height >= 0.0).float()\n",
    "        pressure_weights = inside_mask * (1-self.cop_k*vertex_height) + outside_mask *  torch.exp(-self.cop_w * vertex_height)\n",
    "        cop = torch.sum(vertices_hd * pressure_weights.unsqueeze(-1), dim=1) / (torch.sum(pressure_weights, dim=1, keepdim=True) +eps)\n",
    "\n",
    "        # naive center of support\n",
    "        # vertex_height_robustified = GMoF_unscaled(rho=self.gmof_rho)(vertex_height)\n",
    "        contact_confidence = torch.sum(pressure_weights, dim=1)\n",
    "        # contact_mask = (vertex_height < self.contact_thresh).float()\n",
    "        # num_contact_verts = torch.sum(contact_mask, dim=1)\n",
    "        # contact_centroid_naive = torch.sum(vertices_hd * contact_mask[:, :, None], dim=1) / (torch.sum(contact_mask, dim=1) + eps)\n",
    "\n",
    "        # project com, cop to ground plane (x-z plane)\n",
    "        # weight loss by number of contact vertices to zero out if zero vertices in contact\n",
    "        return com, cop, contact_confidence\n",
    "        \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T12:43:02.836448Z",
     "start_time": "2024-04-08T12:43:02.821480800Z"
    }
   },
   "id": "3b4813a0ececd2",
   "execution_count": 183
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "body_model_config = dict(\n",
    "            type='smplx',\n",
    "            num_betas=10,\n",
    "            use_face_contour=True,\n",
    "            use_pca=False,\n",
    "            flat_hand_mean=True,\n",
    "            model_path='D:/MMLAB/mmhuman3d/data/body_models/smplx',\n",
    "            keypoint_src='smplx',\n",
    "            keypoint_dst='smplx',\n",
    "        )\n",
    "from mmhuman3d.models.body_models.builder import build_body_model\n",
    "body_model = build_body_model(body_model_config)\n",
    "poses = torch.tensor(h_data['smplx']['fullpose'])\n",
    "NUM_JOINTS = body_model.NUM_JOINTS\n",
    "NUM_BODY_JOINTS = body_model.NUM_BODY_JOINTS\n",
    "NUM_DIM = 3 * (NUM_JOINTS + 1)\n",
    "poses = poses.view(poses.shape[0], -1, (NUM_JOINTS + 1) * 3)\n",
    "betas = torch.tensor(h_data['smplx']['betas'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T12:43:04.991367900Z",
     "start_time": "2024-04-08T12:43:04.038335400Z"
    }
   },
   "id": "f2e44ffdfc63be74",
   "execution_count": 184
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pose_dict = body_model.tensor2dict(\n",
    "    full_pose=poses, betas=betas)\n",
    "model_output = body_model(**pose_dict)\n",
    "vertices = model_output['vertices']\n",
    "joints = model_output['joints']\n",
    "faces = body_model.faces\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T12:43:05.082571900Z",
     "start_time": "2024-04-08T12:43:04.995783700Z"
    }
   },
   "id": "928cf271687ed4cc",
   "execution_count": 185
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([98, 10475, 3])"
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertices.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T12:43:06.620259700Z",
     "start_time": "2024-04-08T12:43:06.582675700Z"
    }
   },
   "id": "a8db85fc3cae1b3d",
   "execution_count": 186
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[6890, -1]' is invalid for input of size 3079650",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[189], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m a \u001B[38;5;241m=\u001B[39m StabilityLossCoP(faces \u001B[38;5;241m=\u001B[39m faces, model_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msmpl\u001B[39m\u001B[38;5;124m'\u001B[39m, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 2\u001B[0m com, cop, contact_confidence \u001B[38;5;241m=\u001B[39m \u001B[43ma\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvertices\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\open-mmlab\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[1;32mIn[183], line 106\u001B[0m, in \u001B[0;36mStabilityLossCoP.forward\u001B[1;34m(self, vertices)\u001B[0m\n\u001B[0;32m    104\u001B[0m per_part_volume \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_per_part_volume(vertices)\n\u001B[0;32m    105\u001B[0m \u001B[38;5;66;03m# sample 20k vertices uniformly on the smpl mesh\u001B[39;00m\n\u001B[1;32m--> 106\u001B[0m vertices_hd \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhdfy_op\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhdfy_mesh\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvertices\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    107\u001B[0m \u001B[38;5;66;03m# get volume per vertex id in the hd mesh\u001B[39;00m\n\u001B[0;32m    108\u001B[0m volume_per_vert_hd \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvertex_id_to_part_volume_mapping(per_part_volume, vertices\u001B[38;5;241m.\u001B[39mdevice)\n",
      "Cell \u001B[1;32mIn[182], line 47\u001B[0m, in \u001B[0;36mHDfier.hdfy_mesh\u001B[1;34m(self, vertices)\u001B[0m\n\u001B[0;32m     45\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhd_operator\u001B[38;5;241m.\u001B[39mdevice \u001B[38;5;241m!=\u001B[39m vertices\u001B[38;5;241m.\u001B[39mdevice:\n\u001B[0;32m     46\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhd_operator \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhd_operator\u001B[38;5;241m.\u001B[39mto(vertices\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m---> 47\u001B[0m hd_verts \u001B[38;5;241m=\u001B[39m \u001B[43msparse_batch_mm\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhd_operator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvertices\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mto(torch\u001B[38;5;241m.\u001B[39mfloat)\n\u001B[0;32m     48\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m hd_verts\n",
      "Cell \u001B[1;32mIn[182], line 12\u001B[0m, in \u001B[0;36msparse_batch_mm\u001B[1;34m(m1, m2)\u001B[0m\n\u001B[0;32m     10\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m m2\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# stack m2 into columns: (B x N x K) -> (N, B, K) -> (N, B * K)\u001B[39;00m\n\u001B[1;32m---> 12\u001B[0m m2_stack \u001B[38;5;241m=\u001B[39m \u001B[43mm2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtranspose\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreshape\u001B[49m\u001B[43m(\u001B[49m\u001B[43mm1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     13\u001B[0m result \u001B[38;5;241m=\u001B[39m m1\u001B[38;5;241m.\u001B[39mmm(m2_stack)\u001B[38;5;241m.\u001B[39mreshape(m1\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], batch_size, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m) \\\n\u001B[0;32m     14\u001B[0m            \u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "\u001B[1;31mRuntimeError\u001B[0m: shape '[6890, -1]' is invalid for input of size 3079650"
     ]
    }
   ],
   "source": [
    "a = StabilityLossCoP(faces = faces, model_type='smpl', device='cpu')\n",
    "com, cop, contact_confidence = a(vertices)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T12:43:50.611863300Z",
     "start_time": "2024-04-08T12:43:49.934961200Z"
    }
   },
   "id": "4997b2fd7d494d30",
   "execution_count": 189
  },
  {
   "cell_type": "markdown",
   "source": [
    "# OLD"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1070ca0de33e947d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c3d014b704ff6d8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "det_width, det_height = 224,224\n",
    "focal_length=5000\n",
    "bbox = boxes_xyxy[0]\n",
    "cam_transl = torch.Tensor(pred_cam[0])\n",
    "vertices = torch.Tensor(keypoints[0,:, :3 ])\n",
    "Ks = torch.Tensor(convert_bbox_to_intrinsic(bbox, bbox_format='xyxy'))\n",
    "K = torch.Tensor(\n",
    "    get_default_hmr_intrinsic(\n",
    "        focal_length=focal_length,\n",
    "        det_height=det_height,\n",
    "        det_width=det_width))[0]\n",
    "\n",
    "T = torch.cat([\n",
    "    cam_transl[..., [1]], cam_transl[..., [2]], 2 * focal_length /\n",
    "    (det_width * cam_transl[..., [0]] + 1e-9)\n",
    "], -1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T16:16:23.961049Z",
     "start_time": "2024-04-07T16:16:23.932052500Z"
    }
   },
   "id": "dfab6149f485854c",
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "a = vertices + T"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T16:16:25.349912100Z",
     "start_time": "2024-04-07T16:16:25.329550900Z"
    }
   },
   "id": "881c8c97a7624919",
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[5.5460, 0.0000, 0.1435],\n        [0.0000, 5.5460, 0.0795],\n        [0.0000, 0.0000, 1.0000]])"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ks"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T16:19:21.164690300Z",
     "start_time": "2024-04-07T16:19:21.099947700Z"
    }
   },
   "id": "b5ea76398e07a164",
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# convert 3d keypoints to 2d projections\n",
    "Ks = K.inverse() @ Ks @ K\n",
    "keypoints_proj = Ks @ (vertices+T).T\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T16:16:26.916997800Z",
     "start_time": "2024-04-07T16:16:26.890399500Z"
    }
   },
   "id": "fbc28c054ba4f064",
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 8.13567   ,  7.392222  , 43.811047  ],\n       [ 8.263477  ,  4.7312984 , 43.79423   ],\n       [ 6.9090743 ,  2.7138216 , 43.771545  ],\n       [ 6.9980206 ,  2.7567542 , 44.039524  ],\n       [ 6.4594765 ,  5.290786  , 44.029472  ],\n       [ 3.8655303 ,  6.0134964 , 44.048965  ],\n       [ 6.828209  ,  2.1001434 , 43.59755   ],\n       [ 5.665564  ,  1.282096  , 43.684402  ],\n       [ 6.8601785 ,  0.3234438 , 43.788425  ],\n       [ 7.563809  ,  0.5369147 , 44.058117  ],\n       [ 7.5501266 ,  1.9016277 , 44.2003    ],\n       [ 8.391019  ,  1.900821  , 43.98271   ],\n       [ 7.396494  ,  0.14446223, 43.91024   ],\n       [ 7.7141137 , -0.9741654 , 43.89562   ]], dtype=float32)"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoints_proj.to('cpu').numpy().T"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T16:16:57.109317500Z",
     "start_time": "2024-04-07T16:16:56.982252500Z"
    }
   },
   "id": "d0c05d2544b8bd8f",
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#visualize_3d_keypoints(keypoints_proj.to('cpu').numpy().T, bound = False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T16:20:51.638715800Z",
     "start_time": "2024-04-07T16:20:51.510232200Z"
    }
   },
   "id": "e6a896432d02de86",
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "c = [829.28393555, 509.6375227 ]\n",
    "s = [1242.30453491, 1242.30453491]\n",
    "crop_transform = [[ 2.06068630e-01, -0.00000000e+00, -4.28894046e+01], [-4.28407392e-18,  2.06068638e-01,  2.29796921e+01]]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f561253619189163"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([1.0170028 , 0.12261761, 0.22002508], dtype=float32)"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_data['pred_cams'][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T16:14:41.688896100Z",
     "start_time": "2024-04-07T16:14:41.658683Z"
    }
   },
   "id": "9b1d1a325472ebd5",
   "execution_count": 47
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Other"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee6ea1d0a798e9a2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "def generate_3d_keypoints_video(keypoints_array,M, output_file, fps=30):\n",
    "    # Extracting dimensions\n",
    "    n, k, _ = keypoints_array.shape\n",
    "    \n",
    "    # Initialize figure and 3D axis\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    \n",
    "    \n",
    "    # Setting axis limits (You might need to adjust these based on your data)\n",
    "    ax.set_xlim([-1.2,1.2])\n",
    "    ax.set_ylim([-1.2,1.2])\n",
    "    ax.set_zlim([-1.2,1.2])\n",
    "    \n",
    "    # Initialize empty plot\n",
    "    sc = ax.scatter([], [], [])\n",
    "    # Initialize empty CoM plot\n",
    "    com = ax.scatter([], [], [], c='r', marker='o')\n",
    "    \n",
    "    \n",
    "    # Intialize plot for CoM\n",
    "    # rotate the 3d plot x zero, y zero is at the bottom left\n",
    "    # set origin top left corner\n",
    "    ax.invert_yaxis()\n",
    "    ax.view_init(elev=80, azim=-90,roll=0)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    # Update function for animation\n",
    "    def update_plot(i):\n",
    "        sc._offsets3d = (keypoints_array[i,:,0], keypoints_array[i,:,1], keypoints_array[i,:,2])\n",
    "        com._offsets3d = (M[i,0], M[i,1], M[i,2])      \n",
    "            \n",
    "        # Clear existing text\n",
    "        for txt in ax.texts:\n",
    "            txt.remove()\n",
    "        # add number to each keypoint\n",
    "        for j in range(k):\n",
    "            ax.text(keypoints_array[i,j,0], keypoints_array[i,j,1], keypoints_array[i,j,2], '%s' % (str(j)), size=10, zorder=1, color='k')\n",
    "        return sc, com,\n",
    "\n",
    "    \n",
    "    # Create animation\n",
    "    ani = animation.FuncAnimation(fig, update_plot, frames=n, interval=1000/fps, blit=True)\n",
    "    \n",
    "    # Save animation as video file\n",
    "    ani.save(output_file, writer='ffmpeg', fps=fps, codec='libx264')\n",
    "    plt.close(fig)\n",
    "    \n",
    "\n",
    "generate_3d_keypoints_video(keypoints,M = M,output_file =str(data_root/'3d_keypoints.mp4'), fps=10)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "940227ae9ee05c80"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from mmhuman3d.utils.demo_utils import (\n",
    "    convert_bbox_to_intrinsic,\n",
    "    convert_crop_cam_to_orig_img,\n",
    "    convert_kp2d_to_bbox,\n",
    "    get_default_hmr_intrinsic,\n",
    "    get_different_colors,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7af9ed122199e945"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# extrat first image from video\n",
    "cap = cv2.VideoCapture(str(mesh_vid))\n",
    "w, h = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "plot_keypoints = keypoints[0,:,:2].copy()\n",
    "plot_keypoints= plot_keypoints * h_data['pred_cams'][0][0] + h_data['pred_cams'][0][1]\n",
    "ret, frame = cap.read()\n",
    "cap.release()\n",
    "# plot box on first image\n",
    "box = boxes_xyxy[0]\n",
    "x1, y1, x2, y2,conf = box\n",
    "x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "# extract box width and height and center\n",
    "cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "# plot 2d keypoints on first image (keypoints 2d are relative to the bbox)\n",
    "x1, y1, x2, y2,conf = box\n",
    "# top left of the bbox is -1,-1 and bottom right is 1,1\n",
    "# so we need to convert keypoints to the image coordinate system\n",
    "w,h,c_x,c_y = x2-x1, y2-y1, (x1+x2)/2, (y1+y2)/2\n",
    "for kp in plot_keypoints:\n",
    "    x, y = kp\n",
    "    x, y = int(c_x+x*w), int(c_y+y*h)\n",
    "    cv2.circle(frame, (x, y), 3, (0, 255, 0), -1)\n",
    "\n",
    "    \n",
    "# present image using Image\n",
    "Image.fromarray(frame)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1501491386ff6704"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# plot 2d keypoints on video and export it to output_vid\n",
    "cap = cv2.VideoCapture(str(input_vid))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "w, h = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "out = cv2.VideoWriter(str(output_vid), fourcc, fps, (w, h))\n",
    "frame_idx = 0\n",
    "for i in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_idx += 1\n",
    "    if frame_idx >= keypoints2d.shape[0]:\n",
    "        break\n",
    "    box = boxes_xyxy[frame_idx]\n",
    "    x1, y1, x2, y2,conf = box\n",
    "    w,h,c_x,c_y = x2-x1, y2-y1, (x1+x2)/2, (y1+y2)/2\n",
    "    for kp in keypoints2d[frame_idx]:\n",
    "        x, y = kp\n",
    "        x, y = int(c_x+x*w), int(c_y+y*h)\n",
    "        cv2.circle(frame, (x, y), 3, (0, 255, 0), -1)\n",
    "    out.write(frame)\n",
    "out.release()\n",
    "cap.release()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc5c0574b687982a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "keypoints = h_data['keypoints3d'][:, :, :3]\n",
    "boxes_xyxy = h_data['bbox_xywh']\n",
    "pred_cam = h_data['pred_cams']\n",
    "cap = cv2.VideoCapture(str(input_vid))\n",
    "w, h = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "cap.release()\n",
    "keypoints2d = keypoints[:, :, :2]\n",
    "# kp3d.view(num_frames, -1, 3)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a67acf316628bf56"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
